[
  {
    "objectID": "posts/valentines_spending/index.html",
    "href": "posts/valentines_spending/index.html",
    "title": "Valentine’s Day Spending",
    "section": "",
    "text": "This post focuses on Valentine’s Day spending. The data set contains data for years 2010 to 2022, and the survey asked various questions to consumers on how they planned to celebrate Valentine’s Day. We will investigate the differences in spending between age categories, see if less people are participating in Valentine’s day now than in the past, as well as determine if spending has changed over the years. The data set comes from the tidytuesdayR Github repository (2024, week 7). The data can be found here: https://github.com/rfordatascience/tidytuesday/blob/master/data/2024/2024-02-13/readme.md"
  },
  {
    "objectID": "posts/valentines_spending/index.html#participation",
    "href": "posts/valentines_spending/index.html#participation",
    "title": "Valentine’s Day Spending",
    "section": "Participation",
    "text": "Participation\n\nggplot(data = historical_spending, aes(x = Year, y = PercentCelebrating)) + \n  geom_point(size = 2) + \n  geom_line(alpha = 0.7) + \n  ylim(0,70) + \n  theme_minimal() +\n  ylab(\"Percent of Population Partcipating in Valentine's Day\") +\n  theme(axis.text.x = element_text(size = 15),\n        axis.text.y = element_text(size = 15),\n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 15),\n        title = element_text(size = 12))\n\n\n\n\nIt appears the percentage of people celebrating Valentine’s has slightly decreased since 2010 from roughly 60 percent celebrating to just over 50 percent celebrating. Has this meant a decrease in spending?"
  },
  {
    "objectID": "posts/valentines_spending/index.html#spending",
    "href": "posts/valentines_spending/index.html#spending",
    "title": "Valentine’s Day Spending",
    "section": "Spending",
    "text": "Spending\n\nlibrary(readr)\nvalentines_inflation &lt;- read_csv(\"valentines_inflation.csv\")\n\nRows: 13 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): Year, PerPersonInflation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nggplot(data = historical_spending, aes(x = Year, y = PerPerson)) + \n  geom_point(size = 2) + \n  ylim(0,200) + \n  geom_point(data = valentines_inflation, aes(x = Year, y = PerPersonInflation), color = \"red\", size = 2) + \n  theme_minimal() +\n  ylab(\"Spending Per Participant\") +\n  theme(axis.text.x = element_text(size = 15),\n        axis.text.y = element_text(size = 15),\n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 15),\n        title = element_text(size = 12))\n\n\n\n\nAlthough participation has decreased, this has not coincided with a decrease in spending per person for those who participate. The average spending per person rose from roughly 100 dollars to 175 dollars from 2010 to 2022. Adjusting for inflation* (shown in red), 175 dollars in 2022 was equivalent to 133 dollars in 2010, so there is still a thirty percent increase even after accounting for inflation. Spending is clearly up, but who is spending the most?\n*Used CPI inflation."
  },
  {
    "objectID": "posts/valentines_spending/index.html#spending-by-age",
    "href": "posts/valentines_spending/index.html#spending-by-age",
    "title": "Valentine’s Day Spending",
    "section": "Spending By Age",
    "text": "Spending By Age\n\ngifts_age_total &lt;- gifts_age |&gt; mutate(total_spending = SpendingCelebrating + Candy + Flowers + Jewelry + GreetingCards + EveningOut + Clothing + GiftCards)\n\nggplot(data = gifts_age, aes(x = Age, y = SpendingCelebrating)) + \n  geom_col(fill = \"#DC143C\", color = \"#900C3F\", linewidth = 1) + \n  theme_minimal() +\n  ylab(\"Amount Spend Celebrating (USD)\") +\n  theme(axis.text.x = element_text(size = 15),\n        axis.text.y = element_text(size = 15),\n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 15),\n        title = element_text(size = 12))\n\n\n\n\nIt is clear that order populations spend less than younger populations, which was expected. The youngest group (18-24) spend over twice as much money on celebrating compared to the groups over 45 years old. 65+ individuals only spent around 15.\nSome of the analysis was limited because the underlying data and the sample size are not provided with the data set. The summaries and totals were only provided, which hides a lot of the potential spread.\nAs for applying course content, I have chosen appropriate visuals to make for each of the questions, and have modified the theme to make them more readable and appealing. I also calculated by hand the spending adjusted for inflation to more accurately depict the trend in the data in the second visual. Generally, I have applied the concepts from class to build effective and easy to understand visuals."
  },
  {
    "objectID": "posts/phone_subscriptions/index.html",
    "href": "posts/phone_subscriptions/index.html",
    "title": "Mobile and Landline Phone Subscriptions",
    "section": "",
    "text": "Introduction\nThis blog focuses on a Historical Phone Usage for mobile and land-line phones. The data sets contain 6,267 and 6,964 observation respectively. This blog looks at the adoption of mobile phones in each country from 1990 until 2016. We are looking to examine how different continents adopted mobile technologies. Which continent adopted the quickest and which the slowest? Which continents had the most mobile subscriptions per 100 people in 2016? The data set comes from the tidytuesdayR Github repository (2020, week 46). The data can be found here: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-11-10/readme.md.\n\n\nLook at the Dataframe\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\n\ntuesdata &lt;- tidytuesdayR::tt_load(2020, week = 46)\nraw_mobile &lt;- tuesdata$mobile\n\n\nhead(raw_mobile)\n\n# A tibble: 6 × 7\n  entity      code   year total_pop gdp_per_cap mobile_subs continent\n  &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;    \n1 Afghanistan AFG    1990  13032161          NA           0 Asia     \n2 Afghanistan AFG    1991  14069854          NA           0 Asia     \n3 Afghanistan AFG    1992  15472076          NA           0 Asia     \n4 Afghanistan AFG    1993  17053213          NA           0 Asia     \n5 Afghanistan AFG    1994  18553819          NA           0 Asia     \n6 Afghanistan AFG    1995  19789880          NA           0 Asia     \n\n\n\n\nVisualization\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nraw_mobile$mobile_subs[is.na(raw_mobile$mobile_subs)] &lt;- 0\n\ndata_continent &lt;- raw_mobile |&gt;\n  group_by(continent, year) |&gt;\n  summarise(mobile_subs = mean(mobile_subs))\n\n\nggplot(data = data_continent, aes(x = year, y = mobile_subs, color = continent)) + \n  geom_line(linewidth = 2) + \n  theme_minimal() +\n  labs(title = \"Average Number of Phone Subscriptions in Different Countries\",\n       y = \"Average Number of Phone Subscriptions per 100 People\",\n       x = \"Year\",\n       color = \"Continent\") + \n  theme(axis.text.x = element_text(size = 15),\n        axis.text.y = element_text(size = 15),\n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 10),\n        title = element_text(size = 12))\n\n\n\n\nThe visual shows that Asia was the continent to most quickly adopt mobile technology and Africa was the slowest to adopt it. Africa began to really adopt it almost five years after the rest of the continents did. This doesn’t come as much of a surprise. What is more interesting is that Africa has more phones per person than the Oceania region does. I was not expecting this, but it makes sense since Oceania has many islands that probably don’t have a lot of technological innovation. It is clear that the Americas, Europe, and Asia have embraced the new tech with over 100 phones per 100 people on average for all those regions, whereas Africa and Oceania are lagging behind at only roughly 75 and 55 phones per 100 people respectively.\nI this this approach is flawed in a few ways. First is that one cannot see the underlying data or the sample size that is summarized in the graph with only a mean. Additionally, the continent groupings are very broad. The Americas continent is quite large and includes a multitude of countries with different technological footprints. This goes for many of these continents. If I had more time, I’d examine a select a handful countries to compare from different regions, or compare different countries to each other within a region.\nWe have talked about coloring in homework and in class. In the visual, I used a categorical un-ordered color scale for the un-ordered categorical continents. We talked about different plots, and I think this line plot does a good job a representing this data. The plot was also kept simple and clean to avoid unnecessary clutter. For these reasons, I think this an effective visualization to answer the questions at hand."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DS334blog",
    "section": "",
    "text": "Computer Chip Performance\n\n\n\n\n\n\n\nComputer Science\n\n\nTechnology\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2024\n\n\nLeif Harvey\n\n\n\n\n\n\n  \n\n\n\n\nProgramming Languages\n\n\n\n\n\n\n\nComputer Science\n\n\nProgramming\n\n\nTechnology\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2024\n\n\nLeif Harvey\n\n\n\n\n\n\n  \n\n\n\n\nValentine’s Day Spending\n\n\n\n\n\n\n\nCulture\n\n\nConsumer\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2024\n\n\nLeif Harvey\n\n\n\n\n\n\n  \n\n\n\n\nMobile and Landline Phone Subscriptions\n\n\n\n\n\n\n\nTechnology\n\n\nHistory\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2024\n\n\nLeif Harvey\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome! This blog explores a new data set for the Data Visualization class. I focus my posts on relevant topics, as well topics like technology, economics, and computer science."
  },
  {
    "objectID": "posts/finalproject/index.html",
    "href": "posts/finalproject/index.html",
    "title": "Computer Chip Performance",
    "section": "",
    "text": "Introduction\nThe project will examine performance of CPU and GPU chips made since 2000. The data set includes chips made by multiple vendors such as Intel, NVIDIA, ATI, and AMD. Other variables include the process size, thermal design power, die size, number of transistors, frequency, foundry, and GFLOPS. GFLOPS is a way to compare the performance of graphics cards and stands for a billion floating point operations per second.\nThe full project can be found here: https://github.com/LeifHarvey/DS334_Final_Project/tree/main\n\nchips_origional |&gt; slice(1:5) |&gt; select(2:5, 9:11)\n\n# A tibble: 5 × 7\n  Product   Type  `Release Date` `Process Size (nm)` `Freq (MHz)` Foundry Vendor\n  &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;                        &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; \n1 AMD Athl… CPU   2007-02-20                      65         2200 Unknown AMD   \n2 AMD Athl… CPU   2018-09-06                      14         3200 Unknown AMD   \n3 Intel Co… CPU   2020-09-02                      10         2600 Intel   Intel \n4 Intel Xe… CPU   2013-09-01                      22         1800 Intel   Intel \n5 AMD Phen… CPU   2011-05-03                      45         3700 Unknown AMD   \n\n\n\n\nIs there a Best Foundry?\nOne potential issue when looking a foundries and performance is that the foundries have partnerships with certain vendors, which may be producing better or worse products. Lets go ahead and look anyway with this in mind. The plot is interactive and shows the vendor when the points are hovered over.\n\ngpu &lt;- chips |&gt; filter(!is.na(fp32gflops))\n\nfoundry_glops &lt;- ggplot(data = gpu, aes(x = Foundry, y = fp32gflops, label = Vendor)) + \n  geom_jitter(alpha = 0.5) + \n  theme_minimal() + \n  ylab(\"FP32GFLOPS\") + \n  labs(title = \"Foundry vs FP-32-GFLOPS\",\n       caption = \"GFLOPS represents Billions of Floating Point Operations Per Second\")\n\nggplotly(foundry_glops, tooltip = \"label\")\n\n\n\n\n\nIt appears as Samsung is a proxy for NVIDIA as it mainly produces NVIDIA GPUs. TSMC produces products for everyone but Intel. I’d say Intel mainly focuses on CPUs and many of the GPUs are just integrated ones. GF also has some high performing chips, which are all AMD chips.\n\n\nMoore’s Law\nCo-founder of Fairchild Semiconductor and Co-founder and CEO of Intel Gordon Moore made the observation that the number of transistors in an integrated circuit doubled about every 2 years. In 1965, Moore predicted a doubling every year for at least a decade, and in 1975, Moore changed his prediction to every two years which has held since then. We can look at the number of transistors over the time period of this data set which has chips since 2000.\n\nchips$date &lt;- as.Date(chips$date)\n\nfoundry_glops &lt;- ggplot(data = chips, aes(x = date, y = transistors, label = date)) + \n  geom_point(alpha = 0.5) + \n  theme_minimal() + \n  ylab(\"Transistors\") + \n  labs(title = \"Transistors over Time\") +\n  scale_x_date(date_labels = \"%Y-%m\")\n\nggplotly(foundry_glops, tooltip = \"label\")\n\n\n\n\n\nThe plot shows an exponential trend which indeed lines up with Moore’s prediction. The graph shows that we have really just hit the exponential curve. Looking at this graph with just CPUs we get:\n\nCPU_chips &lt;- chips |&gt; filter(Type == \"CPU\")\n\nfoundry_glops &lt;- ggplot(data = CPU_chips, aes(x = date, y = transistors, label = date)) + \n  geom_point(alpha = 0.5) + \n  theme_minimal() + \n  ylab(\"Transistors\") + \n  labs(title = \"CPU Transistors over Time\") +\n  scale_x_date(date_labels = \"%Y-%m\")\n\nggplotly(foundry_glops, tooltip = \"label\")\n\n\n\n\n\nAnd for GPUs:\n\nGPU_chips &lt;- chips |&gt; filter(Type == \"GPU\")\n\nfoundry_glops &lt;- ggplot(data = GPU_chips, aes(x = date, y = transistors, label = date)) + \n  geom_point(alpha = 0.5) + \n  theme_minimal() + \n  ylab(\"Transistors\") + \n  labs(title = \"GPU Transistors over Time\") +\n  scale_x_date(date_labels = \"%Y-%m\")\n\nggplotly(foundry_glops, tooltip = \"label\")\n\n\n\n\n\nThe ‘law’ holds up for both, but slightly better with GPUs.\n\n\nChip Performance over Time\nLet us look at the performance changes in chips over time. Using the fp32gflops metric which is the number of 32 bit integer floating point operations per second in billions, we s\n\nno_na_g &lt;- chips |&gt; filter(!is.na(fp32gflops))\nno_na_g$date &lt;- as.Date(no_na_g$date)\n\nggplot(data = no_na_g, aes(x = date, y = fp32gflops)) + \n  geom_point() + \n  theme_minimal() + \n  ylab(\"Billion Floating Point Operation per Second\") + \n  xlab(\"Date\") + \n  scale_x_date(date_labels = \"%Y-%m\")\n\n\n\n\nWe see a similar trend here as we did with the transistor count. The number of operations appears to be exponentially increasing with time. What factors are contributing to this?\n\nDie Size\n\nggplot(data = no_na_g, aes(x = die_size, y = fp32gflops)) + \n  geom_point() + \n  theme_minimal() + \n  ylab(\"Billion Floating Point Operation per Second\") + \n  xlab(\"Die Size\")\n\n\n\n\nDie size seems to have an effect on the number of operations per second, but has it increased with time?\n\nggplot(data = no_na_g, aes(x = date, y = die_size)) + \n  geom_point() + \n  theme_minimal() + \n  ylab(\"Die Size\") + \n  xlab(\"Date\") + \n  scale_x_date(date_labels = \"%Y-%m\")\n\n\n\n\nDie size does not seem to have changed much over the last decade, so perhaps it isn’t the culprit of the increased performance.\n\n\nFrequency\n\nggplot(data = no_na_g, aes(x = freq, y = fp32gflops)) + \n  geom_point() + \n  theme_minimal() + \n  ylab(\"Billion Floating Point Operation per Second\") + \n  xlab(\"Frequency\")\n\n\n\n\nFrequency has a distinct effect on the number of operations per second. The higher the frequency the more operations able to be done per second.\n\nggplot(data = no_na_g, aes(x = date, y = freq)) + \n  geom_point() + \n  theme_minimal() + \n  ylab(\"Frequency\") + \n  xlab(\"Date\") + \n  scale_x_date(date_labels = \"%Y-%m\")\n\n\n\n\nUnlike die size, frequency does clearly improve over time in a linear fashion, so this could be one reason for the increased performance.\n\n\nTDP\n\nggplot(data = no_na_g, aes(x = TDP, y = fp32gflops)) + \n  geom_point() + \n  theme_minimal() + \n  ylab(\"Billion Floating Point Operation per Second\") + \n  xlab(\"Thermal Design Power\")\n\n\n\n\nThermal design power doesn’t seem to have a clear effect on the number of operations per second.\n\nggplot(data = no_na_g, aes(x = date, y = TDP)) + \n  geom_point() + \n  theme_minimal() + \n  ylab(\"Thermal Design Power\") + \n  xlab(\"Date\") + \n  scale_x_date(date_labels = \"%Y-%m\")\n\n\n\n\nThermal design power doesn’t appear to play to critical of a role in the improved performance over the last few decades.\n\n\nProcessor Size\n\nggplot(data = no_na_g, aes(x = process_size, y = fp32gflops)) + \n  geom_point() + \n  theme_minimal() + \n  ylab(\"Billion Floating Point Operation per Second\") + \n  xlab(\"Processor Size\")\n\n\n\n\nProcessor size clearly has effect on the number of operations per second. It mimics a exponential decay function; larger processors are exponentially slower.\n\nggplot(data = no_na_g, aes(x = date, y = process_size)) + \n  geom_point() + \n  theme_minimal() + \n  ylab(\"Processor Size\") + \n  xlab(\"Date\") + \n  scale_x_date(date_labels = \"%Y-%m\")\n\n\n\n\nProcessor size seems to play a large role in the improved performance over the last few decades. Chips seem to be decreasing in size at almost the same rate as the number of transistors has been growing.\nOverall, it appears that the number of transistors, the frequency, and the processor size are the main reasons why chip performance has increased year over year. These variables show strong relationships with the performance metric as well as a increase or, in the case of processor size, decrease over time."
  },
  {
    "objectID": "posts/programming_languages/index.html",
    "href": "posts/programming_languages/index.html",
    "title": "Programming Languages",
    "section": "",
    "text": "Introduction\nThis post focuses on programming languages and their popularity. The data set contains information for 4303 languages, and has 48 variables ranging from popularity, to github information, to specifics about each language. Which languages have the most users? Does the type of language has an effect on its popularity? Does the date of release have an effect on the popularity? Do wikipedia metrics coenside with the popularity of a language? The data set comes from the tidytuesdayR Github repository (2023, week 12). The data can be found here: https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-03-21/readme.md\n\n\nA Look at the Data\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(scales)\n\ntuesdata &lt;- tidytuesdayR::tt_load('2023-03-21')\ntuesdata &lt;- tidytuesdayR::tt_load(2023, week = 12)\n\nlanguages &lt;- tuesdata$languages\n\nlanguages |&gt; select(title, type, appeared, book_count, language_rank, wikipedia_daily_page_views, number_of_users, number_of_jobs, features_has_comments, features_has_semantic_indentation)\n\n\n\nWhich Languages have the Most Users?\n\nlanguages_users &lt;- languages |&gt; filter(number_of_users &gt; 100000)\n\np &lt;- ggplot(data = languages_users, aes(x = number_of_users)) + \n  geom_col(aes(y = fct_reorder(title, -number_of_users)), fill = \"lightblue\", color = \"darkblue\") + \n  theme_minimal() + \n  labs(x = \"Number of Users\", y = \"Language\", title = \"Users for Different Languages\") + \n  theme(axis.text.x = element_text(size = 12),\n        axis.text.y = element_text(size = 12),\n        title = element_text(size = 15),\n        axis.title.y = element_text(size = 15),\n        axis.title.x = element_text(size = 15))\n\np + scale_x_continuous(labels = label_comma())\n\n\n\n\nSQL sits atop the leader board along with web languages like Javascript, HTML, and CSS, but also with languages like Java, C++, C, and Python. Cool to see ARM made in onto this list. This list contains languages that are for various applications, so does a language’s type play a role in its popularity?\n\n\nLanguage Type on Language’s Popularity\n\nlanguages_type &lt;- languages |&gt; \n  filter(language_rank &lt; 2000) |&gt; \n  group_by(type) |&gt; \n  summarise(mean_rank = mean(language_rank), group_count = n()) |&gt; \n  filter(group_count &gt;= 5) |&gt;\n  filter(mean_rank &lt; 1500)\n\nggplot(data = languages_type, aes(x = fct_reorder(type, -mean_rank), y = mean_rank)) +\n  geom_col(fill = \"lightblue\", color = \"darkblue\") + \n  coord_flip() + \n  theme_minimal() + \n  labs(x = \"Language Type\", y = \"Mean Rank\", title = \"Mean Rank for Different Language Types\")\n\n\n\n\nI have only used the top 2000 languages for this graphic. When grouping by Language Type, I have removed types that had less than 5 languages. This graph then shows all the language types with a mean rank of less than 1500. Style sheet languages sit on top (languages like CSS), but programming languages (pl) are quite far down the list with a mean rank of a bit over 900. This makes sense since there are so many of them.\n\n\nRelease Date on Languages’s Popularity\n\nlanguages_release &lt;- languages |&gt; filter(appeared &gt; 1925)\n\nrelease_lm &lt;- lm(language_rank ~ appeared, data = languages_release)\n\nggplot(data = languages_release, aes(x = appeared, y = language_rank)) + \n  geom_jitter(width = 0.25, alpha = 0.5) + \n  geom_line(data = release_lm, aes(x = appeared, y = .fitted), linewidth = 2, color = \"red\") +\n  theme_minimal() + \n  labs(x = \"Date Released\", y = \"Language Popularity Rank\")\n\n\n\n\nThe data had some languages that appeared as early as -2000 BCE, and I was interested in new language’s popularity, so I have removed languages released before 1925 (this was less than 15 observation out of 4303). I have plotted a red line which is a linear model predicting the language’s rank based on when it was released It shows that newer languages tend to be more popular. Looking at the data more closely, however, shows that there aren’t many languages released since 2015 that are in the top 250 or so.\n\n\nWikipedia Metrics on Languages’s Popularity\n\nhigh_views &lt;- languages |&gt; filter(wikipedia_daily_page_views &gt; 5000)\nr &lt;- languages |&gt; filter(title == \"R\")\n\nggplot(data = languages, aes(x = wikipedia_daily_page_views, y = language_rank)) + \n  geom_point(alpha = 0.3) + \n  geom_text_repel(data = high_views, aes(label = title), box.padding = 0.5) + \n  geom_text_repel(data = r, aes(label = title), box.padding = 0.5) + \n  theme_minimal() +\n  ylim(0, 3000) + \n  labs(x = \"Daily Wikipedia Page Views\", y = \"Language Popularity Rank\")\n\n\n\n\nThere is a clear non-linear relationship between the number of daily Wikipedia page views and the language’s popularity. There are almost no languages with a lot of daily pages views that are outside the top 500 in languages. Unsurprisingly, Java, C, and Python all are in the top 10 of daily page views. R is also up there with roughly 3000 daily page views."
  }
]